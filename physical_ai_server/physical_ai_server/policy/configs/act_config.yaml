# ACT Policy Configuration  
# Based on LeRobot's configuration_act.py

policy_name: "act"

# Vision Backbone Configuration
vision_backbone:
  name: "resnet18"  # Options: resnet18, resnet34, resnet50, efficientnet_b0, efficientnet_b3
  pretrained: true
  replace_final_stride_with_dilation: false
  
  # ResNet configurations
  resnet18:
    n_channels: 3
    pretrained: true
    replace_final_stride_with_dilation: false
    
  resnet34:
    n_channels: 3
    pretrained: true
    replace_final_stride_with_dilation: false
    
  resnet50:
    n_channels: 3
    pretrained: true
    replace_final_stride_with_dilation: false
    
  # EfficientNet configurations
  efficientnet_b0:
    pretrained: true
    n_channels: 3
    
  efficientnet_b3:
    pretrained: true
    n_channels: 3

# Spatial Softmax Configuration
spatial_softmax:
  enabled: false
  num_kp: null
  learnable_temperature: false
  temperature: 1.0
  noise_std: 0.0

# Transformer Architecture Configuration
transformer:
  # Encoder settings
  encoder:
    num_layers: 4
    num_heads: 8
    feedforward_dim: 2048
    dropout: 0.1
    activation: "relu"  # Options: relu, gelu, silu
    
  # Decoder settings  
  decoder:
    num_layers: 7
    num_heads: 8
    feedforward_dim: 2048
    dropout: 0.1
    activation: "relu"
    
  # Model dimensions
  d_model: 256  # Hidden dimension
  d_kv: 64      # Key-value dimension
  
  # Positional encoding
  positional_encoding:
    max_len: 1000
    dropout: 0.1

# VAE (Variational AutoEncoder) Configuration
vae:
  enabled: true
  
  # Latent space configuration
  latent_dim: 256
  kl_weight: 10.0
  
  # Encoder architecture
  encoder:
    hidden_dims: [512, 1024]
    activation: "relu"
    dropout: 0.1
    
  # Decoder architecture
  decoder:
    hidden_dims: [1024, 512]
    activation: "relu"
    dropout: 0.1
    
  # KL divergence settings
  kl_divergence:
    beta: 1.0
    beta_schedule: "constant"  # Options: constant, linear, cosine
    beta_start: 0.0
    beta_end: 1.0
    warmup_steps: 1000

# Action Chunking Configuration
action_chunking:
  enabled: true
  chunk_size: 100  # Number of future actions to predict
  execution_horizon: 8  # Number of actions to execute per step

# Query and Key Configuration
query_frequency: 1  # Frequency of queries relative to actions

# Crop Configuration for Camera Images
crop:
  enabled: true
  top: 0
  left: 0
  height: 480
  width: 640

# Training Configuration
training:
  # Optimizer settings
  optimizer:
    name: "AdamW"
    lr: 1.0e-5
    weight_decay: 1.0e-4
    betas: [0.9, 0.999]
    eps: 1.0e-8
    
  # Learning rate scheduler
  lr_scheduler:
    name: "cosine"
    warmup_steps: 500
    max_steps: 100000
    
  # Training hyperparameters
  batch_size: 8
  num_epochs: 2000
  gradient_clip_val: 10.0
  
  # Validation settings
  val_check_interval: 250
  save_checkpoint: true
  
  # Loss configuration
  loss:
    name: "l1"  # Options: l1, mse, huber
    reduction: "mean"
    
  # VAE loss weight
  vae_loss_weight: 1.0

# Evaluation Configuration
evaluation:
  n_episodes: 50
  max_episode_steps: 400

# Hardware Configuration  
device:
  type: "auto"  # Options: auto, cpu, cuda, mps
  compile: false  # Whether to use torch.compile

# Model Checkpointing
checkpoint:
  save_dir: "./checkpoints/act"
  save_top_k: 3
  monitor: "val_loss"
  mode: "min"

# Logging Configuration
logging:
  wandb:
    enabled: false
    project: "act_policy"
    entity: null
    
  tensorboard:
    enabled: true
    log_dir: "./logs/act"

# Data Configuration
data:
  image_keys: ["observation.images.cam_high", "observation.images.cam_low", "observation.images.cam_left_wrist", "observation.images.cam_right_wrist"]
  delta_timestamps:
    action: [0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2, 2.4, 2.6, 2.8, 3.0, 3.2, 3.4, 3.6, 3.8, 4.0, 4.2, 4.4, 4.6, 4.8, 5.0, 5.2, 5.4, 5.6, 5.8, 6.0, 6.2, 6.4, 6.6, 6.8, 7.0, 7.2, 7.4, 7.6, 7.8, 8.0, 8.2, 8.4, 8.6, 8.8, 9.0, 9.2, 9.4, 9.6, 9.8, 10.0, 10.2, 10.4, 10.6, 10.8, 11.0, 11.2, 11.4, 11.6, 11.8, 12.0, 12.2, 12.4, 12.6, 12.8, 13.0, 13.2, 13.4, 13.6, 13.8, 14.0, 14.2, 14.4, 14.6, 14.8, 15.0, 15.2, 15.4, 15.6, 15.8, 16.0, 16.2, 16.4, 16.6, 16.8, 17.0, 17.2, 17.4, 17.6, 17.8, 18.0, 18.2, 18.4, 18.6, 18.8, 19.0, 19.2, 19.4, 19.6, 19.8]
    observation.images.cam_high: [0.0]
    observation.images.cam_low: [0.0]
    observation.images.cam_left_wrist: [0.0]
    observation.images.cam_right_wrist: [0.0]
    observation.state: [0.0]

# Environment-specific presets
presets:
  aloha:
    vision_backbone:
      name: "resnet18"
    crop:
      enabled: true
      top: 0
      left: 0
      height: 480
      width: 640
    action_chunking:
      chunk_size: 100
      execution_horizon: 8
    vae:
      enabled: true
      latent_dim: 32
      kl_weight: 10.0
      
  pusht:
    vision_backbone:
      name: "resnet18"
    crop:
      enabled: false
    action_chunking:
      chunk_size: 50
      execution_horizon: 4
    vae:
      enabled: false
      
  xarm:
    vision_backbone:
      name: "resnet18"
    crop:
      enabled: true
      top: 0
      left: 0
      height: 480
      width: 640
    action_chunking:
      chunk_size: 100
      execution_horizon: 8
    vae:
      enabled: true
      latent_dim: 256
      kl_weight: 10.0

# Model Loading Configuration
model_loading:
  pretrained_policy_name_or_path: null  # Path to pretrained ACT model
  revision: "main"
  local_files_only: false
  trust_remote_code: false
  
  # Model format
  save_format: "safetensors"  # Options: safetensors, pytorch
